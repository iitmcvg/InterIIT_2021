{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model_eval.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMXv2rlo+JZNa19ELb1hJg/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iitmcvg/InterIIT_2021/blob/model_eval/model_eval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7U23JhMpeehL"
      },
      "source": [
        "def model_eval(weights_path, img_augmentation):\n",
        "  import tensorflow as tf\n",
        "  from tensorflow import keras\n",
        "  from tensorflow.keras import layers\n",
        "  from tensorflow.keras.layers.experimental import preprocessing\n",
        "  from tensorflow.keras.models import Sequential\n",
        "  from tensorflow.keras.applications import EfficientNetB0\n",
        "  from tqdm.notebook import tqdm\n",
        "  import os\n",
        "  from PIL import Image\n",
        "  import numpy as np\n",
        "\n",
        "  output_dict = {}\n",
        "\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "  IMG_SIZE=224\n",
        "  NUM_CLASSES=48\n",
        "\n",
        "  preprocess_input = tf.keras.applications.efficientnet.preprocess_input\n",
        "  rescale = tf.keras.layers.experimental.preprocessing.Rescaling(1./127.5, offset= -1)\n",
        "\n",
        "  inputs = tf.keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "  x = img_augmentation(inputs)\n",
        "  x = preprocess_input(x)\n",
        "  x = base_model(x, training=False)\n",
        "  x = global_average_layer(x)\n",
        "  x = tf.keras.layers.Dropout(0.2)(x)\n",
        "  outputs = prediction_layer(x)\n",
        "  model = tf.keras.Model(inputs, outputs)\n",
        "  base_learning_rate = 0.001\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\n",
        "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "                metrics=['accuracy'])\n",
        "  \n",
        "  base_model.trainable = True\n",
        "  fine_tune_at = 150\n",
        "  for layer in base_model.layers[:fine_tune_at]:\n",
        "    layer.trainable =  False\n",
        "\n",
        "  model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "              optimizer = tf.keras.optimizers.Adam(lr=base_learning_rate/10),\n",
        "              metrics=['accuracy'])\n",
        "  \n",
        "  model.load_weights(weights_path)\n",
        "\n",
        "  test_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  \"/content/drive/MyDrive/GTSRB/Online-Test-sort\",\n",
        "  seed=123,\n",
        "  image_size=(IMG_SIZE, IMG_SIZE))\n",
        "\n",
        "  y1 = np.array([]) \n",
        "  y2 = np.array([])\n",
        "  for x, y in tqdm(test_dataset):\n",
        "    y_true=np.argmax(model.predict(x),axis=1)\n",
        "    y1=np.append(y1,y_true)\n",
        "    y2=np.append(y2,y.numpy())\n",
        "\n",
        "  from sklearn.metrics import accuracy_score\n",
        "\n",
        "  output_dict.add(\"Test Accuracy:\", accuracy_score(y1, y2)*100)\n",
        "\n",
        "  import seaborn as sns\n",
        "  import pandas as pd\n",
        "  import matplotlib.pyplot as plt\n",
        "  \n",
        "  df_cm = pd.DataFrame(cf)\n",
        "  plt.figure(figsize = (30,30))\n",
        "  sns.heatmap(df_cm, annot=True)\n",
        "  plt.savefig(\"cf_matrix.png\")\n",
        "\n",
        "  output_dict.add(\"Confusion Matrix file path:\", \"/content/cf_matrix.png\")\n",
        "\n",
        "  from sklearn.metrics import classification_report\n",
        "  \n",
        "  output_dict.add(\"Classification report:\", classification_report(y1, y2))\n",
        "\n",
        "  import heapq\n",
        "\n",
        "  top5softmax = np.zeros((len(test_dataset), 5))\n",
        "  i = 0\n",
        "  for x, y in tqdm(test_dataset):\n",
        "    top5softmax[i] = heapq.nlargest(5, range(NUM_CLASSES), model.predict(x).take)\n",
        "    i = i+1\n",
        "\n",
        "  import pandas as pd\n",
        "  top5_dataframe = pd.DataFrame(top5softmax, columns = ['1', '2', '3', '4', '5'])\n",
        "  confusion_matrix = pd.crosstab(top5_dataframe['1'], top5_dataframe['2'], rownames=['Best class'], colnames=['Second best class'])\n",
        "  plt.figure(figsize = (30,30))\n",
        "  sns.heatmap(confusion_matrix, annot=True)\n",
        "  plt.savefig(\"Top_2_classes.png\")\n",
        "\n",
        "  output_dict.add(\"Top 2 classes matrix\", \"/content/Top_2_classes.png\")\n",
        "\n",
        "  return output_dict"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}